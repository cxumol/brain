<div id="content"><p>The <strong>Bayesian information criterion</strong> (BIC) or <strong>Schwarz information criterion</strong> (SIC) is a criterion for <a href="model-selection">model selection</a> in a finite set of models. We prefer the model with the lowest BIC. Its general defenition is</p>

<p>$$ \text{BIC} = \log N\cdot d - 2\ \text{loglik} ,$$</p>

<p>where $N$ is the number of data points $d$ is the number of parameters estimated by the model and $\text{loglik}$ is the log of the maximized <a href="likelihood-function">likelihood function</a>.</p>

<p>Sources:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Wikipedia</a></li>
<li><a href="the-elements-of-statistical-learning">The Elements of Statistical Learning</a></li>
</ul>

<div class="backlinks">

<h2 id="backlinks">Backlinks</h2>

<ul>
<li><a href="stk-in4300-lecture-02---linear-methods-for-regression">STK-IN4300 Lecture 02 - Linear methods for regression</a></li>
</ul>

</div>
</div>