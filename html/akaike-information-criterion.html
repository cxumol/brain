<div id="content"><hr />

<p>type: Journal</p>

<h2 id="modified-2020-09-17t0930320200">modified: 2020-09-17T09:30:32+02:00</h2>

<p>The <strong>Akaike information criterion</strong> (AIC) is an <a href="estimator">estimator</a> of out-of-sample prediction error, and thus a measure of quality of statistical models, for a given set of data. Its defenition is</p>

<p>$$ \text{AIC} = 2d - 2\text{loglik} ,$$</p>

<p>where $d$ is the number of parameters estimated by the model and $\text{loglik}$ is the log of the maximized <a href="likelihood-function">likelihood function</a>.</p>

<p>Sources:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Wikipedia</a></li>
<li><a href="the-elements-of-statistical-learning">The Elements of Statistical Learning</a></li>
</ul>

<div class="backlinks">

<h2 id="backlinks">Backlinks</h2>

<ul>
<li><a href="stk-in4300-lecture-02---linear-methods-for-regression">STK-IN4300 Lecture 02 - Linear methods for regression</a></li>
</ul>

</div>
</div>